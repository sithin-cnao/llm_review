{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c2fa1c-9679-44b1-8031-7841094b7749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"COHERE_API_KEY\"] = 'E2efronXbGqXSR0sclyInSjXptFOjdIjsbCeXFwP'\n",
    "\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb97c0e-9c92-4fce-9d5e-bf610f278077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_pymupdf4llm import PyMuPDF4LLMLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf03dac-4475-4d72-8c5b-31dffd287ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285177dc-6b12-41ef-8d40-020ecf8e8714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab6be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "XL_PATH = r\"../dataset/screening/articles_to_screen.csv\"\n",
    "OUT_DIR = r\"../dataset/screening/ai_decision.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a218ac-142b-4c58-bbd5-b8da6a2cf64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# screened abstracts\n",
    "\n",
    "df = pd.read_csv(XL_PATH)[[\"key\", \"title\", \"abstract\"]]\n",
    "\n",
    "display(df.head())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df739b17-65ec-47b2-afa7-0c0ec23ceba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputSchema(BaseModel):\n",
    "    thoughts: str = Field(description= \"thoughts of the model\")\n",
    "    decision: int = Field(description=\"1 if the abstract was selected, 0 otherwise\")\n",
    "    reason: str = Field(description = \"generate a consise one sentence long reason for the decision\")\n",
    "\n",
    "\n",
    "# llm = ChatCohere(model=\"command-r\", temperature=0.0)\n",
    "llm = ChatOllama(model=\"deepseek-r1:32b\", temperature=0.0, num_ctx=5_000)\n",
    "struct_llm = llm.with_structured_output(OutputSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b93de-f8a1-4465-864d-97a7616f895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#     ('system',  \"You are a helpful AI agent that assists in accurately screening the article using its abstract. \" \n",
    "#                 \"Based solely on the abstract provided, determine whether the article discusses an APPLICATION OF AI METHODS IN CARBON ION THERAPY? \"\n",
    "#                 \"Your decision should be '0' for NO or '1' for YES. Then, generate a concise, one-sentence reason for your decision.\"\n",
    "#     ),\n",
    "#     ('human', \"abstract:\\n\\n title: {title}, \\n content: {abstract}\")\n",
    "#   ]\n",
    "\n",
    "messages = [\n",
    "    ('system',  \"You are a helpful AI assistant that accurately screens and SELECTS articles relevant to given TOPIC, for inclusion in a literature review, based solely on their ABSTRACT. \" \n",
    "                \"Your decision should be '1' for YES or '0' otherwise. Then, generate a concise, one-sentence reason for your decision.\"\n",
    "    ),\n",
    "    ('human', \"TOPIC: APPLICATIONS OF AI METHODS IN CARBON ION THERAPY\\n\\nABSTRACT:\\n\\n title: {title}, \\n content: {abstract}\")\n",
    "  ]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "chain = prompt_template | struct_llm\n",
    "\n",
    "decision_df = {\"key\":[], \"title\":[], \"abstract\":[], \"decision\":[], \"reason\":[], \"thoughts\":[]}\n",
    "\n",
    "rows = [row.to_dict() for i,row in df.iterrows()][:5]\n",
    "\n",
    "for row in tqdm(rows):\n",
    "  # key, title, selection = row.to_dict()[\"key\"], row.to_dict()[\"title\"], row.to_dict()[\"selection\"]\n",
    "\n",
    "  inputs = {key:row[key] for key in [\"title\", \"abstract\"]} \n",
    "\n",
    "  output = chain.invoke(inputs)\n",
    "\n",
    "  for key,val in {**row, **dict(output)}.items():\n",
    "      decision_df[key].append(val)\n",
    "  \n",
    "decision_df = pd.DataFrame(decision_df)\n",
    "if not os.path.exists(OUT_DIR):\n",
    "   os.makedirs(OUT_DIR)\n",
    "decision_df.to_csv(os.path.join(OUT_DIR, \"ai_decision.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d37cd8-105c-4011-a658-1aea8dc936b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this doesn't work very well\n",
    "# from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# file_path = r\"1-s2.0-S1120179724002163-main.pdf\"\n",
    "# loader = PyPDFLoader(file_path, mode='single')\n",
    "# pages = []\n",
    "# async for page in loader.alazy_load():\n",
    "#     pages.append(page)\n",
    "\n",
    "# manuscript = \"\\n\".join([page.page_content for page in pages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymupdf4llm\n",
    "\n",
    "# file_path = r\"1-s2.0-S1120179724002163-main.pdf\"\n",
    "# manuscript = pymupdf4llm.to_markdown(file_path)\n",
    "\n",
    "# ref_index = manuscript.lower().find(\"references\")\n",
    "\n",
    "# # Keep everything up to and including \"References\"\n",
    "# if ref_index != -1:\n",
    "#     manuscript = manuscript[:ref_index + len(\"references\")]\n",
    "\n",
    "# # Now md_text contains only up to the References section\n",
    "# print(manuscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a56742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class OutputSchema(BaseModel):\n",
    "#     thoughts: str = Field(description= \"thoughts of the model\")\n",
    "#     study_objective: str = Field(description=\"The objective of the article\")\n",
    "#     ai_methods: str = Field(description=\"The AI method(s) used in the article in the context of carbon ion therapy. Describe each AI method at least in one sentence\")\n",
    "#     application_domain: str = Field(description=\"the specific carbon ion therapy application domain\")\n",
    "#     dataset_characteristics: str = Field(description=\"characteristics of the dataset, including the training, validation, test split; also external validation information, if present\")\n",
    "#     key_findings: str = Field(description=\"key findings mentioned in the article\")\n",
    "#     pros_and_cons: str = Field(description=\"strengths and limitations of the study\")\n",
    "#     future_direction: str = Field(description=\"future directions (if stated)\")\n",
    "\n",
    "# llm = ChatCohere(model='command-r', temperature=0.0)\n",
    "# # llm = ChatOllama(model=\"deepseek-r1:32b\", temperature=0.0)\n",
    "# struct_llm = llm.with_structured_output(OutputSchema)\n",
    "\n",
    "# messages = [\n",
    "#     ('system',  \"You are a helpful AI agent that assists in accurately summarizing the article in a standardized format \"\n",
    "#                 \"to be used for the literature review titled 'APPLICATIONS OF AI IN CARBON ION THERAPY'. \\n\"\n",
    "#                 \"Summarize the article under the following standard headers:\\n\"\n",
    "#                 \"'1. Study objective', '2. AI methods used', '3. carbon therapy application domain', '4. Dataset characteristics', '5. Key findings', \"\n",
    "#                 \"'6. Strengths and limitations', '7. Future directions (if stated)' \"\n",
    "#     ),\n",
    "#     ('human', \"article: \\n {article}\")\n",
    "#   ]\n",
    "\n",
    "# prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "# chain = prompt_template | struct_llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f383046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OutputSchema(BaseModel):\n",
    "    thoughts: str = Field(description=\"thoughts before answering the questions\")\n",
    "    aim: str = Field(description=\"answer to Q1. What is the aim of this study?\")\n",
    "    category: str = Field(description=\"answer to Q2. Which of the following categories does this article belong to: treatment planning, tumor control prediction, normal tissue complication prediction, or unknown\")\n",
    "    dataset: str = Field(description=\"answer to Q3. Describe the dataset and provide the training, validation and test strategy involved in AI modelling, including the corresponding sample counts.\")\n",
    "    ai_methodology: str = Field(description=\"answer to Q4. Define the AI methodology used by the authors for their analysis\")\n",
    "    pros_and_cons: str = Field(description=\"answer to Q5. What are the strengths and weaknesses of the methodology followed?\")\n",
    "    results: str = Field(description=\"answer to Q6. Can you summarize the results in terms of the performance metrics and check how appropriate the metrics were to evaluate the AI model?\")\n",
    "    arguments: str = Field(description=\"answer to Q7. What are the strong and weak arguments that the authors are pointing out in the discussion?\")\n",
    "    conclusion: str = Field(description=\"answer to Q8. What is their conclusion, and what are their main arguments to support it?\")\n",
    "    critical_summary: str = Field(description=\"answer to Q9. Can you generate a CRITICAL_SUMMARY combining all the ANSWERS in 300 characters?\")\n",
    "\n",
    "# llm = ChatCohere(model='command-r', temperature=0.0)\n",
    "llm = ChatOllama(model=\"deepseek-r1:32b\", temperature=0.0, num_ctx=15_000)\n",
    "struct_llm = llm.with_structured_output(OutputSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef04b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# import json\n",
    "# schema_str = json.dumps(OutputSchema.model_json_schema())\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\")\n",
    "# len(tokenizer.encode(schema_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3a5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = ''''\n",
    "You are a helpful AI reviewer tasked to perform a concise literature review of an ARTICLE for the specified REVIEW_TOPIC.\n",
    "Carefully read the entire ARTICLE and generate a CRITICAL_SUMMARY by accurately answering each of the QUESTIONS below.\n",
    "\n",
    "QUESTIONS:\n",
    "Q1. What is the aim of this study?\n",
    "Q2. Which of the following categories does this article belong to: treatment planning, tumor control prediction, normal tissue complication prediction, or unknown\n",
    "Q3. Describe the dataset and provide the training, validation and test strategy involved in AI modelling, including the corresponding sample counts.\n",
    "Q4. Define the AI methodology used by the authors for their analysis.\n",
    "Q5. What are the strengths and weaknesses of the methodology followed?\n",
    "Q6. Can you summarize the results in terms of the performance metrics and check how appropriate the metrics were to evaluate the AI model?\n",
    "Q7. What are the strong and weak arguments that the authors are pointing out in the discussion?\n",
    "Q8. What is their conclusion, and what are their main arguments to support it?\n",
    "\n",
    "Answer each question solely using the information directly available in the ARTICLE. \n",
    "The ANSWERS should be detailed, evidence-based and written in an objective and academic tone appropriate for a scientific literature review. \n",
    "If specific information required to answer any question is not present in the ARTICLE, state this clearly instead of speculating.\n",
    "\n",
    "Can you generate a CRITICAL_SUMMARY combining all the ANSWERS in 300 characters?\n",
    "'''\n",
    "\n",
    "human_message = \"ARTICLE:\\n{article}\\n\\nREVIEW_TOPIC:{topic}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ('system', system_message),\n",
    "    ('human', human_message)\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "chain = prompt_template | struct_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ef7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "\n",
    "ARTICLE_DIR = r\"../dataset/articles\"\n",
    "\n",
    "file_paths = [os.path.join(ARTICLE_DIR, file) for file in os.listdir(ARTICLE_DIR) if file.endswith(\".pdf\")][:2]\n",
    "\n",
    "for file_path in tqdm(file_paths):\n",
    "    loader = PyMuPDF4LLMLoader(file_path, mode='single') #we are loading all the pages of the documents in a single page\n",
    "    docs = loader.load()\n",
    "    manuscript = docs[0].page_content\n",
    "    \n",
    "    \n",
    "    # Keep everything except contents inside \"References\"\n",
    "    ref_index = manuscript.lower().find(\"references\")\n",
    "    if ref_index != -1:\n",
    "        manuscript = manuscript[:ref_index + len(\"references\")]\n",
    "\n",
    "    output = dict(chain.invoke({\"article\":manuscript, \"topic\":\"APPLICATIONS OF AI METHODS IN CARBON ION THERAPY\"}))\n",
    "    output[\"file_path\"] = file_path\n",
    "\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2f466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20145305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline, AutoConfig\n",
    "# from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
    "# from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# model_name = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\" #\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\"\n",
    "\n",
    "# config = AutoConfig.from_pretrained(model_name)\n",
    "# pipe = pipeline(\"text-generation\", model=model_name, max_new_tokens=2048, device=1, do_sample=False) #temperature = 0.0 since do_sample is False\n",
    "# llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "\n",
    "# # print(config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
