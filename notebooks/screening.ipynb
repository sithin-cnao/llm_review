{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c2fa1c-9679-44b1-8031-7841094b7749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"COHERE_API_KEY\"] = 'E2efronXbGqXSR0sclyInSjXptFOjdIjsbCeXFwP'\n",
    "\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb97c0e-9c92-4fce-9d5e-bf610f278077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acf03dac-4475-4d72-8c5b-31dffd287ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "285177dc-6b12-41ef-8d40-020ecf8e8714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab6be61",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "XL_PATH = r\"../dataset/screening/articles_to_screen.csv\"\n",
    "OUT_DIR = r\"../dataset/screening/ai_decision.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a218ac-142b-4c58-bbd5-b8da6a2cf64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# screened abstracts\n",
    "\n",
    "df = pd.read_csv(XL_PATH)[[\"key\", \"title\", \"abstract\"]]\n",
    "\n",
    "display(df.head())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df739b17-65ec-47b2-afa7-0c0ec23ceba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputSchema(BaseModel):\n",
    "    thoughts: str = Field(description= \"thoughts of the model\")\n",
    "    decision: int = Field(description=\"1 if the abstract was selected, 0 otherwise\")\n",
    "    reason: str = Field(description = \"generate a consise one sentence long reason for the decision\")\n",
    "\n",
    "\n",
    "llm = ChatCohere(model=\"command-r\", temperature=0.0)\n",
    "# llm = ChatOllama(model=\"deepseek-r1:32b\", temperature=0.0)\n",
    "struct_llm = llm.with_structured_output(OutputSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b93de-f8a1-4465-864d-97a7616f895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# messages = [\n",
    "#     ('system',  \"You are a helpful AI agent that assists in accurately screening the article using its abstract. \" \n",
    "#                 \"Based solely on the abstract provided, determine whether the article discusses an APPLICATION OF AI METHODS IN CARBON ION THERAPY? \"\n",
    "#                 \"Your decision should be '0' for NO or '1' for YES. Then, generate a concise, one-sentence reason for your decision.\"\n",
    "#     ),\n",
    "#     ('human', \"abstract:\\n\\n title: {title}, \\n content: {abstract}\")\n",
    "#   ]\n",
    "\n",
    "messages = [\n",
    "    ('system',  \"You are a helpful AI assistant that accurately screens and SELECTS articles relevant to given TOPIC, for inclusion in a literature review, based solely on their ABSTRACT. \" \n",
    "                \"Your decision should be '1' for YES or '0' otherwise. Then, generate a concise, one-sentence reason for your decision.\"\n",
    "    ),\n",
    "    ('human', \"TOPIC: APPLICATIONS OF AI METHODS IN CARBON ION THERAPY\\n\\nABSTRACT:\\n\\n title: {title}, \\n content: {abstract}\")\n",
    "  ]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "chain = prompt_template | struct_llm\n",
    "\n",
    "decision_df = {\"key\":[], \"title\":[], \"abstract\":[], \"decision\":[], \"reason\":[], \"thoughts\":[]}\n",
    "\n",
    "rows = [row.to_dict() for i,row in df.iterrows()][:5]\n",
    "\n",
    "for row in tqdm(rows):\n",
    "  # key, title, selection = row.to_dict()[\"key\"], row.to_dict()[\"title\"], row.to_dict()[\"selection\"]\n",
    "\n",
    "  inputs = {key:row[key] for key in [\"title\", \"abstract\"]} \n",
    "\n",
    "  output = chain.invoke(inputs)\n",
    "\n",
    "  for key,val in {**row, **dict(output)}.items():\n",
    "      decision_df[key].append(val)\n",
    "  \n",
    "decision_df = pd.DataFrame(decision_df)\n",
    "if not os.path.exists(OUT_DIR):\n",
    "   os.makedirs(OUT_DIR)\n",
    "decision_df.to_csv(os.path.join(OUT_DIR, \"ai_decision.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3632a5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d37cd8-105c-4011-a658-1aea8dc936b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this doesn't work very well\n",
    "# from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# file_path = r\"1-s2.0-S1120179724002163-main.pdf\"\n",
    "# loader = PyPDFLoader(file_path, mode='single')\n",
    "# pages = []\n",
    "# async for page in loader.alazy_load():\n",
    "#     pages.append(page)\n",
    "\n",
    "# manuscript = \"\\n\".join([page.page_content for page in pages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymupdf4llm\n",
    "\n",
    "# file_path = r\"1-s2.0-S1120179724002163-main.pdf\"\n",
    "# manuscript = pymupdf4llm.to_markdown(file_path)\n",
    "\n",
    "# ref_index = manuscript.lower().find(\"references\")\n",
    "\n",
    "# # Keep everything up to and including \"References\"\n",
    "# if ref_index != -1:\n",
    "#     manuscript = manuscript[:ref_index + len(\"references\")]\n",
    "\n",
    "# # Now md_text contains only up to the References section\n",
    "# print(manuscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6a6881",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# docs = []\n",
    "# for doc in docs_lazy:\n",
    "#     docs.append(doc)\n",
    "\n",
    "# manuscript = docs[0].page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a56742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class OutputSchema(BaseModel):\n",
    "#     thoughts: str = Field(description= \"thoughts of the model\")\n",
    "#     study_objective: str = Field(description=\"The objective of the article\")\n",
    "#     ai_methods: str = Field(description=\"The AI method(s) used in the article in the context of carbon ion therapy. Describe each AI method at least in one sentence\")\n",
    "#     application_domain: str = Field(description=\"the specific carbon ion therapy application domain\")\n",
    "#     dataset_characteristics: str = Field(description=\"characteristics of the dataset, including the training, validation, test split; also external validation information, if present\")\n",
    "#     key_findings: str = Field(description=\"key findings mentioned in the article\")\n",
    "#     pros_and_cons: str = Field(description=\"strengths and limitations of the study\")\n",
    "#     future_direction: str = Field(description=\"future directions (if stated)\")\n",
    "\n",
    "# llm = ChatCohere(model='command-r', temperature=0.0)\n",
    "# # llm = ChatOllama(model=\"deepseek-r1:32b\", temperature=0.0)\n",
    "# struct_llm = llm.with_structured_output(OutputSchema)\n",
    "\n",
    "# messages = [\n",
    "#     ('system',  \"You are a helpful AI agent that assists in accurately summarizing the article in a standardized format \"\n",
    "#                 \"to be used for the literature review titled 'APPLICATIONS OF AI IN CARBON ION THERAPY'. \\n\"\n",
    "#                 \"Summarize the article under the following standard headers:\\n\"\n",
    "#                 \"'1. Study objective', '2. AI methods used', '3. carbon therapy application domain', '4. Dataset characteristics', '5. Key findings', \"\n",
    "#                 \"'6. Strengths and limitations', '7. Future directions (if stated)' \"\n",
    "#     ),\n",
    "#     ('human', \"article: \\n {article}\")\n",
    "#   ]\n",
    "\n",
    "# prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "# chain = prompt_template | struct_llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f383046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OutputSchema(BaseModel):\n",
    "    thoughts: str = Field(description= \"thoughts of the model\")\n",
    "    Q1_answer: str = Field(description=\"answer to Q1.What is the aim of this study?\")\n",
    "    Q2_answer: str = Field(description=\"answer to Q2. Which of the following categories does this article belong to: treatment planning, tumor control prediction, normal tissue complication prediction, or generative AI\")\n",
    "    Q3_answer: str = Field(description=\"answer to Q3. Describe the dataset and provide the training, validation and test strategy involved in AI modelling, including the corresponding sample counts. \")\n",
    "    Q4_answer: str = Field(description=\"answer to Q4. Define the AI methodology used by the authors in this category\")\n",
    "    Q5_answer: str = Field(description=\"answer to Q5. What are the strengths and weaknesses of the methodology followed? \")\n",
    "    Q6_answer: str = Field(description=\"answer to Q6. Can you summarize the results in terms of the performance metrics and check how appropriate the metrics were to evaluate the AI model? \")\n",
    "    Q7_answer: str = Field(description=\"answer to Q7. What are the strong and weak arguments that the authors are pointing out in the discussion\")\n",
    "    Q8_answer: str = Field(description=\"answer to Q8. What is their conclusion, and what are their main arguments to support it? \")\n",
    "    Q9_answer: str = Field(description=\"answer to Q9. Can you generate a critical summary combining all this information in 300 characters?\")\n",
    "\n",
    "# llm = ChatCohere(model='command-r', temperature=0.0)\n",
    "llm = ChatOllama(model=\"deepseek-r1:32b\", temperature=0.0)\n",
    "struct_llm = llm.with_structured_output(OutputSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8525f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ('system', '''You are an expert AI agent that can perform concise yet accurate review on the input ARTICLE excluding the abstract by answering the following questions: Q1-Q9 \n",
    "                Q1. What is the aim of this study? \n",
    "                Q2. Which of the following categories does this article belong to: treatment planning, tumor control prediction, normal tissue complication prediction, or generative AI \n",
    "                Q3. Describe the dataset and provide the training, validation and test strategy involved in AI modelling, including the corresponding sample counts. \n",
    "                Q4. Define the AI methodology used by the authors in this category \n",
    "                Q5. What are the strengths and weaknesses of the methodology followed? \n",
    "                Q6. Can you summarize the results in terms of the performance metrics and check how appropriate the metrics were to evaluate the AI model? \n",
    "                Q7. What are the strong and weak arguments that the authors are pointing out in the discussion \n",
    "                Q8. What is their conclusion, and what are their main arguments to support it? \n",
    "                Q9. Can you generate a critical summary combining all this information in 300 characters? '''\n",
    "     ),\n",
    "     ('human', \"ARTICLE: \\n {article}\")\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "chain = prompt_template | struct_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88be220-0455-4908-b3c4-2da0508a0ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pymupdf4llm import PyMuPDF4LLMLoader\n",
    "\n",
    "file_path = r\"1-s2.0-S1120179724002163-main.pdf\"\n",
    "loader = PyMuPDF4LLMLoader(file_path, mode='single') #we are loading all the pages of the documents in a single page\n",
    "docs = loader.load()\n",
    "manuscript = docs[0].page_content\n",
    "output = chain.invoke({\"article\":manuscript})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be172857",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
