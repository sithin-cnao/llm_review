{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c2fa1c-9679-44b1-8031-7841094b7749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"COHERE_API_KEY\"] = 'E2efronXbGqXSR0sclyInSjXptFOjdIjsbCeXFwP'\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_pymupdf4llm import PyMuPDF4LLMLoader\n",
    "\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab6be61",
   "metadata": {},
   "outputs": [],
   "source": [
    "XL_PATH = r\"../dataset/screening/articles_to_screen.csv\"\n",
    "OUT_DIR = r\"results\"\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a218ac-142b-4c58-bbd5-b8da6a2cf64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rayyan-97865221</td>\n",
       "      <td>Responsive Magnetic Particle Imaging Tracer: O...</td>\n",
       "      <td>Magnetic particle imaging (MPI) has emerged as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rayyan-97865222</td>\n",
       "      <td>The role of apoptosis, immunogenic cell death,...</td>\n",
       "      <td>Keloids, characterized by excessive extracellu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rayyan-97865224</td>\n",
       "      <td>Particle tracking, recognition and LET evaluat...</td>\n",
       "      <td>Objective. This study aims to assess the compo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rayyan-97865227</td>\n",
       "      <td>Understanding Relative Biological Effectivenes...</td>\n",
       "      <td>Purpose: Recent experimental studies and clini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rayyan-97865228</td>\n",
       "      <td>Use of parvovirus B19-like particles in self-i...</td>\n",
       "      <td>Bioluminescence resonance energy transfer phot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               key                                              title  \\\n",
       "0  rayyan-97865221  Responsive Magnetic Particle Imaging Tracer: O...   \n",
       "1  rayyan-97865222  The role of apoptosis, immunogenic cell death,...   \n",
       "2  rayyan-97865224  Particle tracking, recognition and LET evaluat...   \n",
       "3  rayyan-97865227  Understanding Relative Biological Effectivenes...   \n",
       "4  rayyan-97865228  Use of parvovirus B19-like particles in self-i...   \n",
       "\n",
       "                                            abstract  \n",
       "0  Magnetic particle imaging (MPI) has emerged as...  \n",
       "1  Keloids, characterized by excessive extracellu...  \n",
       "2  Objective. This study aims to assess the compo...  \n",
       "3  Purpose: Recent experimental studies and clini...  \n",
       "4  Bioluminescence resonance energy transfer phot...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413\n"
     ]
    }
   ],
   "source": [
    "# screened abstracts\n",
    "\n",
    "df = pd.read_csv(XL_PATH)[[\"key\", \"title\", \"abstract\"]]\n",
    "\n",
    "display(df.head())\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df739b17-65ec-47b2-afa7-0c0ec23ceba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputSchema(BaseModel):\n",
    "    thoughts: str = Field(description= \"thoughts of the model\")\n",
    "    decision: int = Field(description=\"1 if the article is selected, 0 otherwise\")\n",
    "    reason: str = Field(description = \"generate a consise one sentence long reason for the decision\")\n",
    "    keywords: str = Field(description=\"list all the important keywords associated with the decision\")\n",
    "\n",
    "\n",
    "# llm = ChatCohere(model=\"command-r\", temperature=0.0)\n",
    "llm = ChatOllama(model=\"deepseek-r1:32b\", temperature=0.0, num_ctx=5_000)\n",
    "struct_llm = llm.with_structured_output(OutputSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e0b93de-f8a1-4465-864d-97a7616f895a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa54792348c546ac9cdc284c559c57d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# messages = [\n",
    "#     ('system',  \"You are a helpful AI agent that assists in accurately screening the article using its abstract. \" \n",
    "#                 \"Based solely on the abstract provided, determine whether the article discusses an APPLICATION OF AI METHODS IN CARBON ION THERAPY? \"\n",
    "#                 \"Your decision should be '0' for NO or '1' for YES. Then, generate a concise, one-sentence reason for your decision.\"\n",
    "#     ),\n",
    "#     ('human', \"abstract:\\n\\n title: {title}, \\n content: {abstract}\")\n",
    "#   ]\n",
    "\n",
    "messages = [\n",
    "    ('system',  \"You are a helpful AI assistant that accurately screens and SELECTS ORIGINAL RESEARCH ARTICLES relevant to given literature review TOPIC, based solely on their ABSTRACT.\" \n",
    "                \"Your decision should be '1' if SELECTED or '0' otherwise.\"\n",
    "                \"Generate a concise, one-sentence reason to motivate your decision. Also list the important keywords associated with the decision.\"\n",
    "                \"**NOTE: make sure that the selected article falls within the scope of the review TOPIC**\"\n",
    "    ),\n",
    "    ('human', \"ABSTRACT:\\n\\n title: {title}, \\n content: {abstract}\\n\\n TOPIC: APPLICATIONS OF AI METHODS IN CARBON ION THERAPY\")\n",
    "  ]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "chain = prompt_template | struct_llm\n",
    "\n",
    "decision_df = {\"key\":[], \"title\":[], \"abstract\":[], \"decision\":[], \"keywords\":[], \"reason\":[], \"thoughts\":[]}\n",
    "\n",
    "rows = [row.to_dict() for i,row in df.iterrows()]\n",
    "\n",
    "for row in tqdm(rows):\n",
    "  # key, title, selection = row.to_dict()[\"key\"], row.to_dict()[\"title\"], row.to_dict()[\"selection\"]\n",
    "\n",
    "  inputs = {key:row[key] for key in [\"title\", \"abstract\"]} \n",
    "\n",
    "  output = chain.invoke(inputs)\n",
    "\n",
    "  for key,val in {**row, **dict(output)}.items():\n",
    "      decision_df[key].append(val)\n",
    "  \n",
    "decision_df = pd.DataFrame(decision_df)\n",
    "if not os.path.exists(OUT_DIR):\n",
    "   os.makedirs(OUT_DIR)\n",
    "decision_df.to_csv(os.path.join(OUT_DIR, \"ai_decision.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1c375d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(decision_df[decision_df.decision==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d37cd8-105c-4011-a658-1aea8dc936b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3f289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this doesn't work very well\n",
    "# from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "# file_path = r\"1-s2.0-S1120179724002163-main.pdf\"\n",
    "# loader = PyPDFLoader(file_path, mode='single')\n",
    "# pages = []\n",
    "# async for page in loader.alazy_load():\n",
    "#     pages.append(page)\n",
    "\n",
    "# manuscript = \"\\n\".join([page.page_content for page in pages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymupdf4llm\n",
    "\n",
    "# file_path = r\"1-s2.0-S1120179724002163-main.pdf\"\n",
    "# manuscript = pymupdf4llm.to_markdown(file_path)\n",
    "\n",
    "# ref_index = manuscript.lower().find(\"references\")\n",
    "\n",
    "# # Keep everything up to and including \"References\"\n",
    "# if ref_index != -1:\n",
    "#     manuscript = manuscript[:ref_index + len(\"references\")]\n",
    "\n",
    "# # Now md_text contains only up to the References section\n",
    "# print(manuscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a56742",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class OutputSchema(BaseModel):\n",
    "#     thoughts: str = Field(description= \"thoughts of the model\")\n",
    "#     study_objective: str = Field(description=\"The objective of the article\")\n",
    "#     ai_methods: str = Field(description=\"The AI method(s) used in the article in the context of carbon ion therapy. Describe each AI method at least in one sentence\")\n",
    "#     application_domain: str = Field(description=\"the specific carbon ion therapy application domain\")\n",
    "#     dataset_characteristics: str = Field(description=\"characteristics of the dataset, including the training, validation, test split; also external validation information, if present\")\n",
    "#     key_findings: str = Field(description=\"key findings mentioned in the article\")\n",
    "#     pros_and_cons: str = Field(description=\"strengths and limitations of the study\")\n",
    "#     future_direction: str = Field(description=\"future directions (if stated)\")\n",
    "\n",
    "# llm = ChatCohere(model='command-r', temperature=0.0)\n",
    "# # llm = ChatOllama(model=\"deepseek-r1:32b\", temperature=0.0)\n",
    "# struct_llm = llm.with_structured_output(OutputSchema)\n",
    "\n",
    "# messages = [\n",
    "#     ('system',  \"You are a helpful AI agent that assists in accurately summarizing the article in a standardized format \"\n",
    "#                 \"to be used for the literature review titled 'APPLICATIONS OF AI IN CARBON ION THERAPY'. \\n\"\n",
    "#                 \"Summarize the article under the following standard headers:\\n\"\n",
    "#                 \"'1. Study objective', '2. AI methods used', '3. carbon therapy application domain', '4. Dataset characteristics', '5. Key findings', \"\n",
    "#                 \"'6. Strengths and limitations', '7. Future directions (if stated)' \"\n",
    "#     ),\n",
    "#     ('human', \"article: \\n {article}\")\n",
    "#   ]\n",
    "\n",
    "# prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "# chain = prompt_template | struct_llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f383046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OutputSchema(BaseModel):\n",
    "    thoughts: str = Field(description=\"thoughts of the model\")\n",
    "    aim: str = Field(description=\"answer to q1: aim of the research article\")\n",
    "    category: str = Field(description=\"answer to q2: article category\")\n",
    "    dataset: str = Field(description=\"answer to q3: dataset description and the strategy associated with training, validation and test involved in AI modelling. Also provide the sample counts associated with the train, val and test set.\")\n",
    "    ai_methodology: str = Field(description=\"answer to q4: the AI methodology used by the authors for their analysis\")\n",
    "    pros_and_cons: str = Field(description=\"answer to q5: the strengths and weaknesses of the methodology followed\")\n",
    "    results: str = Field(description=\"answer to q6: summary of the results in terms of the performance metrics and the appropriateness of the metrics were to evaluate the AI model.\")\n",
    "    arguments: str = Field(description=\"answer to q7: the strong and weak arguments that the authors are pointing out in the discussion\")\n",
    "    conclusion: str = Field(description=\"answer to q8. their conclusion, and main arguments to support it\")\n",
    "    critical_summary: str = Field(description=\"a critical summary combining the answers for q1-q8\")\n",
    "    short_summary: str = Field(description=\"a concise critical summary limited 300 characters, including spaces\")\n",
    "\n",
    "# llm = ChatCohere(model='command-r', temperature=0.0)\n",
    "llm = ChatOllama(model=\"deepseek-r1:32b\", temperature=0.0, num_ctx=15_000)\n",
    "struct_llm = llm.with_structured_output(OutputSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef04b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# import json\n",
    "# schema_str = json.dumps(OutputSchema.model_json_schema())\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\")\n",
    "# len(tokenizer.encode(schema_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf3a5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = ''''\n",
    "You are an expert AI reviewer tasked to perform a concise yet accurate literature review of the provided ARTICLE for the specified REVIEW_TOPIC.\n",
    "Carefully read the entire ARTICLE (exluding the abstract) and generate a CRITICAL_SUMMARY and a SHORT_SUMMARY by accurately answering each of the QUESTIONS below.\n",
    "\n",
    "QUESTIONS:\n",
    "q1. What is the aim of this study?\n",
    "q2. Select the most appropriate category the article belong to from the LIST below? \n",
    "    LIST:  ['Treatment planning, optimization and verification', 'Synthetic imaging', 'Tumor control probability (TCP) prediction', 'Normal tissue complication probability (NTCP) prediction']\n",
    "    - Treatment planning, optimization, and verification\n",
    "        *Focus:* all processes before treatment delivery, including treatment dose prediction, dose planning, plan optimization, dose calculation, and plan verification\n",
    "    - Synthetic imaging \n",
    "        *Focus:* generating/transforming images for treatment planning or dose delivery.\n",
    "    - Tumour control probability (TCP) prediction \n",
    "        *Focus:* modelling tumor response to the treatment\n",
    "    - Normal tissue complication probability (NTCP) prediction\n",
    "        *Focus:* adverse events/toxicities/complications/quality-of-life after treatment.\n",
    "    If the study falls into multiple categories, select the one stated as the **primary endpoint**; if not stated, choose the one most emphasized in the title and/or aim. \n",
    "    **Do not include your reasoning or deliberation process in the answer for q2. **\n",
    "q3. Describe the dataset and provide the training, validation and test strategy involved in AI modelling, including the corresponding sample counts.\n",
    "q4. Define the AI methodology used by the authors for their analysis.\n",
    "q5. What are the strengths and weaknesses of the methodology followed?\n",
    "q6. Can you summarize the results in terms of the performance metrics and assess whether the authors chose appropriate metrics to evaluate the AI model?\n",
    "q7. What are the strong and weak arguments that the authors are pointing out in the discussion?\n",
    "q8. What is their conclusion, and what are their main arguments to support it?\n",
    "\n",
    "Answer each question accurately using the information directly available in the ARTICLE. \n",
    "If specific information required to answer any question is not present in the ARTICLE, state this clearly instead of speculating.\n",
    "The ANSWERS should be detailed, evidence-based and written in an objective and academic tone appropriate for a scientific literature review. \n",
    "\n",
    "The CRITICAL_SUMMARY should integrate the answers to q1-q8 into a coherent, structured review.\n",
    "The SHORT_SUMMARY should be a compressed version of CRITICAL_SUMMARY, limited to 300 characters (including spaces).\n",
    "'''\n",
    "\n",
    "human_message = \"ARTICLE:\\n{article}\\n\\nREVIEW_TOPIC:{topic}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8525f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ('system', system_message),\n",
    "    ('human', human_message)\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "chain = prompt_template | struct_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32967fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0ef7317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3170f77d02de47ed9924420d205ba3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal tissue complication probability (NTCP) prediction selected_articles/Zhang_Predicting_Weight_Loss_PT_2018_JJCO.pdf The study aims to predict critical weight loss in cancer patients undergoing particle therapy by identifying key predictors and building a prediction model.\n",
      "Synthetic imaging selected_articles/Parrella_SyntCT_CIRT_Abdomen_Bioeng_2023.pdf The aim is to evaluate if a cGAN can generate synthetic CTs for CIRT in abdominal sites, supporting MRI-only workflows.\n",
      "Treatment planning, optimization and verification selected_articles/Zhang_DL_Denoising_MC_DoseCalculationCIRT_MP_2023.pdf The study aims to evaluate the feasibility of using deep learning-based Monte Carlo (MC) denoising methods to accelerate plan verification in carbon ion radiotherapy by reducing simulation time while maintaining accuracy.\n",
      "Treatment planning, optimization and verification selected_articles/Yabe_DoseDistribPrediction_DL_PT_2020_MP.pdf The aim of this study is to predict dose distributions from luminescence images using a deep convolutional neural network (DCNN) for particle therapy, including protons and carbon ions.\n",
      "Tumour control probability (TCP) prediction selected_articles/Parrella_Dosiomics_CIRT_SBC_PhyMed_2024.pdf The aim is to investigate the role of dosiomics features from physical dose, RBE-weighted dose, and LETd maps in predicting local recurrence (LR) in skull base chordomas treated with CIRT. They also developed TCP models using these features and compared them to clinical models.\n",
      "Synthetic imaging selected_articles/AnestisNakas_DL_SyntCT_4DCT_MRI_Abdomen_CIRT_PhMed_2025.pdf The aim of this study is to investigate the feasibility of deep-learning-based synthetic 4DCT (4D-sCT) generation from 4DMRI data for patients undergoing Carbon Ion Radiotherapy (CIRT). The goal is to support treatment planning by creating accurate synthetic CT volumes that can be used in place of traditional 4DCT scans, thereby reducing radiation exposure and improving workflow efficiency.\n",
      "Tumour control probability (TCP) prediction selected_articles/Wu_Imaging_ResponsePrediction_CIRT_Prostate_cmar_2019.pdf The aim of this study is to explore the value of pre-treatment MRI radiomic features in predicting individualized therapeutic responses to carbon ion radiotherapy (CIRT) for prostate cancer patients.\n",
      "Treatment planning, optimization and verification selected_articles/Quarz_DL_Sampling_TPS_PMB_2024_new.pdf The study aims to develop a deep learning model for voxel sampling in carbon ion therapy treatment planning to reduce computational complexity while maintaining plan quality.\n",
      "Normal tissue complication probability (NTCP) prediction selected_articles/Li_NTCP_Dermatitis_HNC_CIRT_RedJ_2022.pdf The aim of this study was to develop an NTCP model for acute radiation dermatitis (ARD) in patients with head and neck cancer treated with carbon ion radiation therapy, identifying prognostic factors associated with ARD.\n",
      "Normal tissue complication probability (NTCP) prediction selected_articles/Meng_NTCP_HNC_CIRT_rad_dosiomics_012025.pdf The aim of this study is to develop a normal tissue complication probability (NTCP) model for predicting grade ≥2 acute oral mucositis (AOM) in head and neck cancer patients undergoing carbon ion radiation therapy (CIRT). The model integrates dosimetry, radiomics, and dosiomics data to improve prediction accuracy and assist in clinical decision-making.\n",
      "Tumour control probability (TCP) prediction selected_articles/Morelli_Dosiomics_LET_Dose_LR_SacralChordoma_CIRT_cancers_2023.pdf The aim of this study is to apply dosiomics analysis using biological dose and LETd maps to predict local recurrence in sacral chordomas after carbon-ion radiotherapy. They used survival models (r-Cox and s-SVM) with features from these maps to identify prognostic factors.\n",
      "Tumor control probability (TCP) prediction selected_articles/Qiu_Comparative_ML_Cox_Progression_HGGlioma_PT_CIRT_fonc_2020.pdf The aim of this study is to compare the performance of machine learning (Random Survival Forest) and classic statistics (Cox Proportional Hazards) in predicting tumor progression in high-grade glioma patients after proton and carbon ion radiotherapy. The primary focus is on evaluating which method provides better accuracy, precision, and interpretability for clinical deployment.\n",
      "Synthetic imaging selected_articles/Zhang_DR_only_CIRT_TPS_DL_PhyMed_2022.pdf The aim of the study is to evaluate the feasibility of using deep learning to generate predicted CT images from a single DR image for carbon-ion radiotherapy treatment planning in both phantom and patient datasets. The authors sought to develop a workflow that could reduce the need for repeated CT scans, thereby lowering radiation exposure and improving treatment efficiency.\n",
      "Treatment planning, optimization and verification selected_articles/He_Deep learning‐based Monte Carlo dose prediction for heavy‐ion online adaptive radiotherapy_MP_2025.pdf The aim of this study is to develop a deep learning (DL) model for predicting Monte Carlo (MC) doses in heavy-ion radiotherapy (HIT), specifically targeting online adaptive radiotherapy (OART) and rapid quality assurance (QA). The proposed model, CAM-CHD U-Net, integrates a channel attention mechanism into an improved 3D U-Net architecture to enhance dose prediction accuracy and efficiency.\n",
      "Tumour control probability (TCP) prediction selected_articles/Buizza_Radiomics_Dosiomics_LC_SBC_CIRT_Cancers_2020.pdf The aim of the study is to explore the role of radiomic, dosiomic, and clinical features as prognostic factors for local control (LC) in skull-base chordoma (SBC) patients treated with carbon-ion radiotherapy (CIRT).\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "\n",
    "ARTICLE_DIR = r\"selected_articles\"\n",
    "\n",
    "file_paths = [os.path.join(ARTICLE_DIR, file) for file in os.listdir(ARTICLE_DIR) if file.endswith(\".pdf\")]\n",
    "\n",
    "for file_path in tqdm(file_paths):\n",
    "    loader = PyMuPDF4LLMLoader(file_path, mode='single') #we are loading all the pages of the documents in a single page\n",
    "    docs = loader.load()\n",
    "    manuscript = docs[0].page_content\n",
    "\n",
    "    # Keep everything except contents inside \"References\"\n",
    "    pattern = re.compile(r'^[#\\*\\s]*references\\b', re.IGNORECASE | re.MULTILINE)\n",
    "    match = pattern.search(manuscript)\n",
    "    if match:\n",
    "        ref_index = match.start()\n",
    "        manuscript = manuscript[:ref_index + len(match.group(0))]\n",
    "\n",
    "  \n",
    "\n",
    "    output = dict(chain.invoke({\"article\":manuscript, \"topic\":\"APPLICATIONS OF AI METHODS IN CARBON ION THERAPY\"}))\n",
    "    output[\"file_path\"] = file_path\n",
    "\n",
    "    print(output[\"category\"], file_path, output['aim'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5c7ef49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thoughts': \"Okay, so I need to help this user by providing a literature review based on the provided article. The topic is applications of AI methods in carbon ion therapy. Let me start by understanding what each part of the query requires. They want a CRITICAL_SUMMARY and a SHORT_SUMMARY, both answering specific questions about the study. The questions are from q1 to q8, covering aim, category, dataset, methodology, strengths/weaknesses, results, arguments, and conclusion. I need to make sure each answer is accurate and based on the article provided. Also, the CRITICAL_SUMMARY should integrate all these answers into a coherent review, while the SHORT_SUMMARY is a concise version limited to 300 characters. I'll go through each question one by one, extract the necessary information from the article, and structure the responses appropriately. It's important to be objective and evidence-based, avoiding any speculation where data isn't available. Let me start with q1: What is the aim of this study? The abstract mentions exploring radiomic and dosiomic features as prognostic factors for local control in SBC patients undergoing CIRT. So that's clear. Next, q2 asks to categorize the article into one of four categories. The primary focus seems to be on predicting tumor response, so it falls under TCP prediction. Moving on to q3 about the dataset: 57 patients were analyzed with imaging and clinical data split into development (80%) and test sets (20%). For q4, the AI methods used include s-SVM and r-Cox models with various feature selection routines. Strengths and weaknesses in q5 would involve the robustness of the models against overfitting but limited by sample size. Results in q6 show good C-indices for dosiomic features, which is appropriate. The discussion points out strong arguments about dosiomics' promise and weak ones like small sample size. Finally, the conclusion supports multi-parametric approaches with a need for validation. I'll structure all this into the required summaries, ensuring clarity and conciseness.\",\n",
       " 'aim': 'The aim of the study is to explore the role of radiomic, dosiomic, and clinical features as prognostic factors for local control (LC) in skull-base chordoma (SBC) patients treated with carbon-ion radiotherapy (CIRT).',\n",
       " 'category': 'Tumour control probability (TCP) prediction',\n",
       " 'dataset': 'The study analyzed data from 57 SBC patients treated with CIRT. The dataset included pre-treatment MRI and CT imaging, dose maps, and clinical information. It was split into a development set (80%, n=45) for model training and validation, and a hold-out test set (20%, n=12) to evaluate performance on unseen data.',\n",
       " 'ai_methodology': 'The study employed two survival models: linear survival support vector machines (s-SVM) and Cox proportional hazards models regularized with an elastic net penalty (r-Cox). Various feature selection routines were applied to radiomic, dosiomic, and clinical features. The dataset was preprocessed with bias field correction and intensity normalization for MRI images.',\n",
       " 'pros_and_cons': 'Strengths include the use of multi-parametric approaches combining imaging, dose, and clinical data, which enhances prognostic power. The study also validates models on a hold-out test set to assess generalizability. Weaknesses include the relatively small sample size (57 patients), which may limit statistical power and overfitting concerns. Additionally, the retrospective nature of the study introduces potential biases.',\n",
       " 'results': 'Dosiomic features showed the best performance with validation C-indices of 0.80/0.24 for s-SVM and 0.79/0.26 for r-Cox. Combined models (comboAll) also performed well, though slightly inferior to dosiomic-only models. The study used appropriate metrics like the concordance index (C-index) and log-rank tests to evaluate model performance.',\n",
       " 'arguments': 'Strong arguments include the identification of dose heterogeneity as a significant factor in LC outcomes and the potential clinical utility of multi-parametric models. Weak points are the small sample size, which may affect generalizability, and the need for external validation across different institutions.',\n",
       " 'conclusion': 'The study concludes that dosiomic and combined radiomic features show promise in predicting LC after CIRT. However, further validation with larger datasets and multi-institutional studies is necessary before clinical application.',\n",
       " 'critical_summary': 'This study investigates the use of radiomics, dosiomics, and clinical data to predict local control (LC) outcomes in skull-base chordoma patients treated with carbon-ion radiotherapy (CIRT). The primary aim was to explore these features as prognostic factors. The dataset comprised 57 patients, split into development (80%) and test sets (20%). AI methodologies included s-SVM and r-Cox models with various feature selection routines. Strengths of the approach include multi-parametric integration and validation on unseen data; however, limitations such as sample size and retrospective design were noted. Results indicated that dosiomic features, particularly those describing dose heterogeneity, performed best, with C-indices around 0.80 for s-SVM and 0.79 for r-Cox. The study highlights the potential of these models but underscores the need for external validation and larger datasets to confirm findings.',\n",
       " 'short_summary': 'The study explores radiomic and dosiomic features to predict local control in skull-base chordoma patients undergoing CIRT. Using AI models, it finds that dose heterogeneity is a significant factor, with promising results from multi-parametric approaches. However, external validation is needed due to the small sample size.',\n",
       " 'file_path': 'selected_articles/Buizza_Radiomics_Dosiomics_LC_SBC_CIRT_Cancers_2020.pdf'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd771bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fpdf import FPDF\n",
    "\n",
    "\n",
    "# def clean_text(text):\n",
    "#     return text.encode('latin-1', errors='replace').decode('latin-1')\n",
    "\n",
    "# # Create PDF\n",
    "# pdf = FPDF()\n",
    "# pdf.add_page()\n",
    "# pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "\n",
    "# for heading, text in output.items():\n",
    "#     # Add heading\n",
    "#     pdf.set_font(\"Arial\", 'B', 14)\n",
    "#     pdf.cell(0, 10, heading, ln=True)\n",
    "    \n",
    "#     # Add text\n",
    "#     pdf.set_font(\"Arial\", size=12)\n",
    "#     pdf.multi_cell(0, 10, clean_text(text))\n",
    "#     pdf.ln(5)  # Add some space\n",
    "\n",
    "# pdf.output(os.path.join(\"results\", \"output.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f2ae59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20145305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline, AutoConfig\n",
    "# from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
    "# from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# model_name = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\" #\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\"\n",
    "\n",
    "# config = AutoConfig.from_pretrained(model_name)\n",
    "# pipe = pipeline(\"text-generation\", model=model_name, max_new_tokens=2048, device=1, do_sample=False) #temperature = 0.0 since do_sample is False\n",
    "# llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "\n",
    "# # print(config)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
