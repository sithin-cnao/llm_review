{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c82c7615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_pymupdf4llm import PyMuPDF4LLMLoader\n",
    "\n",
    "from pydantic import BaseModel, Field, constr\n",
    "from typing import Literal, List, Optional\n",
    "\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b85c735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_PATH = r\"../database\"\n",
    "OUT_DIR = r\"results\"\n",
    "if not os.path.exists(OUT_DIR):\n",
    "    os.makedirs(OUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455ccd3a",
   "metadata": {},
   "source": [
    "### AI Screening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a218ac-142b-4c58-bbd5-b8da6a2cf64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# screened abstracts\n",
    "\n",
    "df = pd.read_csv(os.path.join(DB_PATH, \"articles_to_screen.csv\"))[[\"key\", \"title\", \"abstract\"]]\n",
    "\n",
    "display(df.head())\n",
    "print(\"# of articles to screen = \", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2deda70",
   "metadata": {},
   "source": [
    "### Abstract Screening by LLM Reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df739b17-65ec-47b2-afa7-0c0ec23ceba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputSchema(BaseModel):\n",
    "    thoughts: str = Field(description= \"thoughts of the model\")\n",
    "    decision: int = Field(description=\"1 if the article is SELECTED, 0 otherwise\")\n",
    "    reason: str = Field(description = \"generate a consise one sentence long reason for the decision\")\n",
    "    ai_method_list: Optional[List[str]] = Field(default=None, description=\"list all the AI methods explored in the article\")\n",
    "\n",
    "\n",
    "# llm = ChatCohere(model=\"command-r\", temperature=0.0)\n",
    "llm = ChatOllama(model=\"deepseek-r1:32b\", temperature=0.0, num_ctx=5_000)\n",
    "struct_llm = llm.with_structured_output(OutputSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0b93de-f8a1-4465-864d-97a7616f895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "messages = [\n",
    "    ('system',  \"You are a helpful AI reviewer that ACCURATELY SCREENS and SELECTS 'ORIGINAL RESEARCH ARTICLES' that falls within the scope of the given 'TOPIC', based on their ABSTRACT.\" \n",
    "                \"Your decision should be '1' if SELECTED or '0' otherwise.\"\n",
    "                \"Generate a concise, one-sentence reason to motivate your decision.\"\n",
    "                \"If selected, list all the AI methods explored in the ORIGINAL RESEARCH ARTICLE.\"\n",
    "                \"**Note: ORIGINAL RESEARCH ARTICLES do NOT include REVIEW ARTICLES. Be precise and objective in your evaluation.**\"\n",
    "    ),\n",
    "    ('human', \"ABSTRACT:\\n\\n title: {title}, \\n content: {abstract}\\n\\n TOPIC: APPLICATIONS OF AI IN CARBON ION THERAPY\")\n",
    "  ]\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "chain = prompt_template | struct_llm\n",
    "\n",
    "decision_df = {\"key\":[], \"title\":[], \"abstract\":[], \"decision\":[], \"ai_method_list\":[], \"reason\":[], \"thoughts\":[]}\n",
    "\n",
    "rows = [row.to_dict() for _,row in df.iterrows()]\n",
    "\n",
    "for row in tqdm(rows):\n",
    "    # key, title, selection = row.to_dict()[\"key\"], row.to_dict()[\"title\"], row.to_dict()[\"selection\"]\n",
    "\n",
    "    inputs = {key:row[key] for key in [\"title\", \"abstract\"]} \n",
    "\n",
    "    output = chain.invoke(inputs)\n",
    "\n",
    "    for key,val in {**row, **dict(output)}.items():\n",
    "        decision_df[key].append(val)\n",
    "\n",
    "decision_df = pd.DataFrame(decision_df)\n",
    "decision_df.to_csv(os.path.join(OUT_DIR, \"ai_decision.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e349d36f",
   "metadata": {},
   "source": [
    "### Complete Critical Review by LLM Reviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f383046",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OutputSchema(BaseModel):\n",
    "    thoughts: str = Field(description=\"thoughts of the model\")\n",
    "    aim: str = Field(description=\"answer to q1: aim of the research article\")\n",
    "    category: Literal[\"Treatment planning, optimization and verification\",\n",
    "        \"Synthetic imaging\",\n",
    "        \"Tumor control probability (TCP) prediction\",\n",
    "        \"Normal tissue complication probability (NTCP) prediction\"] = Field(description=\"answer to q2: article category selected from the predefined LIST\")\n",
    "    dataset: str = Field(description=\"answer to q3: dataset description and the strategy associated with training, validation and test involved in AI modelling. Also provide the sample counts associated with the train, val, and test sets.\")\n",
    "    ai_methodology: str = Field(description=\"answer to q4: the AI methodology used by the authors for their analysis\")\n",
    "    ai_method_list: List[str] = Field(description=\"followup answer to q4: list of ai methodologies used by the authors for their analysis\")\n",
    "    pros_and_cons: str = Field(description=\"answer to q5: the strengths and weaknesses of the methodology followed\")\n",
    "    results: str = Field(description=\"answer to q6: summary of the results in terms of the performance metrics and the appropriateness of the metrics used to evaluate the AI model.\")\n",
    "    arguments: str = Field(description=\"answer to q7: the strong and weak arguments that the authors are point out in the discussion\")\n",
    "    conclusion: str = Field(description=\"answer to q8. their conclusion, and main arguments to support it\")\n",
    "    critical_summary: str = Field(description=\"a critical summary combining the answers for q1-q8\")\n",
    "    short_summary: str = Field(description=\"A concise critical summary limited to **300 characters**\")\n",
    "    \n",
    "\n",
    "# llm = ChatCohere(model='command-r', temperature=0.0)\n",
    "llm = ChatOllama(model=\"deepseek-r1:32b\", temperature=0.0, num_ctx=15_000)\n",
    "struct_llm = llm.with_structured_output(OutputSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef04b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# import json\n",
    "# schema_str = json.dumps(OutputSchema.model_json_schema())\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B\")\n",
    "# len(tokenizer.encode(schema_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf3a5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = ''''\n",
    "You are an expert AI reviewer tasked to perform an accurate literature review of the provided ARTICLE for the specified REVIEW_TOPIC.\n",
    "Carefully read the entire ARTICLE (excluding the abstract) and answer each of the QUESTIONS precisely and strictly based on the information presented in the ARTICLE.\n",
    "Then, generate a CRITICAL_SUMMARY that integrates all of your answers, followed by a SHORT_SUMMARY that provides a concise 300-character-long compressed version of the CRITICAL_SUMMARY.\n",
    "\n",
    "QUESTIONS:\n",
    "q1. What is the aim of this study?\n",
    "q2. Select the single most appropriate category for the article from the LIST below.\n",
    "    LIST:\n",
    "    - Treatment planning, optimization and verification\n",
    "        Focus: processes before treatment delivery, such as dose prediction, treatment planning, plan optimization, dose calculation, and plan verification.\n",
    "    - Synthetic imaging\n",
    "        Focus: generating or transforming images for treatment planning or dose delivery.\n",
    "    - Tumor control probability (TCP) prediction\n",
    "        Focus: modeling tumor response to treatment.\n",
    "    - Normal tissue complication probability (NTCP) prediction\n",
    "        Focus: adverse events, toxicities, complications, or quality-of-life after treatment.\n",
    "    **Selection Rules:**\n",
    "    i. If the study fits multiple categories, select the one explicitly stated as the primary endpoint.\n",
    "    ii. If no primary endpoint is stated, choose the category most emphasized in the title and/or aim.\n",
    "    iii. The answer must be exactly one element from the LIST above.\n",
    "    iv. Do not include reasoning or deliberation in the answer. Only output the category name.\n",
    "\n",
    "q3. Describe the dataset and provide the training, validation, and test strategy involved in AI modelling, including the corresponding sample counts.\n",
    "q4. Define the AI methodology used by the authors in their analysis and list all AI methods that they explored.\n",
    "q5. What are the strengths and weaknesses of the methodology followed?\n",
    "q6. Can you summarize the results in terms of the performance metrics and assess whether the authors chose appropriate metrics to evaluate the AI model?\n",
    "q7. What are the strong and weak arguments that the authors are pointing out in the discussion?\n",
    "q8. What is their conclusion, and what are their main arguments to support it?\n",
    "\n",
    "Answer each question accurately using the information solely available in the ARTICLE. \n",
    "If specific information required to answer any question is not present in the ARTICLE, state this clearly instead of speculating.\n",
    "The ANSWERS should be detailed, evidence-based and written in an objective and academic tone appropriate for a scientific literature review. \n",
    "\n",
    "The CRITICAL_SUMMARY should integrate the answers to q1-q8 into a coherent, structured review.\n",
    "The SHORT_SUMMARY should be a compressed version of CRITICAL_SUMMARY, limited to 300 characters (including spaces).\n",
    "'''\n",
    "\n",
    "human_message = \"ARTICLE:\\n{article}\\n\\nREVIEW_TOPIC:{topic}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8525f4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    ('system', system_message),\n",
    "    ('human', human_message)\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "chain = prompt_template | struct_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe576793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52a162746a94ba4bc13fc25da08b17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic imaging ../database/selected_articles/Zhang_DR_only_CIRT_TPS_DL_PhyMed_2022.pdf The aim is to evaluate if it's possible to use just DR images with deep learning for treatment planning in carbon ion radiotherapy, using a phantom and head-and-neck patients.\n",
      "Synthetic imaging ../database/selected_articles/Parrella_SyntCT_CIRT_Abdomen_Bioeng_2023.pdf The aim is to evaluate the feasibility of generating synthetic CT (sCT) volumes for carbon ion radiotherapy (CIRT) in abdominal sites using a conditional GAN (cGAN). The study focuses on creating sCT from MRI scans to avoid additional radiation exposure and improve treatment planning accuracy.\n",
      "Synthetic imaging ../database/selected_articles/Knausl_synthetic_CT_in_adapative_CIRT.pdf The aim is to explore using synthetic CT (sCT) in carbon-ion therapy for better workflow efficiency without extra imaging dose, despite challenges like patient positioning and limited data.\n",
      "Synthetic imaging ../database/selected_articles/Pepa_syntheticCT from CBCT.pdf To provide a concise summary of the article's key findings and implications regarding the use of AI in carbon ion therapy, focusing on how CycleGAN improves synthetic CT generation for adaptive particle therapy.\n",
      "Synthetic imaging ../database/selected_articles/AnestisNakas_DL_SyntCT_4DCT_MRI_Abdomen_CIRT_PhMed_2025.pdf The aim of this study is to investigate the feasibility of using deep learning to generate synthetic 4DCT from 4DMRI data for patients undergoing Carbon Ion Radiotherapy (CIRT). The goal is to support treatment planning without additional radiation exposure by leveraging MRI's soft tissue contrast and dynamic capabilities.\n",
      "Tumor control probability (TCP) prediction ../database/selected_articles/Wu_Imaging_ResponsePrediction_CIRT_Prostate_cmar_2019.pdf The aim is to explore how pre-treatment MRI radiomic features can predict individual responses to CIRT for prostate cancer patients.\n",
      "Tumor control probability (TCP) prediction ../database/selected_articles/Qiu_Comparative_ML_Cox_Progression_HGGlioma_PT_CIRT_fonc_2020.pdf The aim of this study is to compare the performance of Random Survival Forest (RSF) and Cox Proportional Hazards (CPH) models in predicting progression-free survival (PFS) for high-grade glioma (HGG) patients treated with particle beam radiotherapy (PBRT). The goal is to determine which method is more effective for clinical deployment.\n",
      "Tumor control probability (TCP) prediction ../database/selected_articles/Buizza_Radiomics_Dosiomics_LC_SBC_CIRT_Cancers_2020.pdf The aim of this study is to explore the role of multi-parametric radiomic, dosiomic, and clinical features as prognostic factors for local control (LC) in patients with skull-base chordoma (SBC) treated with carbon-ion radiotherapy (CIRT). The researchers aimed to develop predictive models using these features to better understand treatment outcomes.\n",
      "Tumor control probability (TCP) prediction ../database/selected_articles/Morelli_Dosiomics_LET_Dose_LR_SacralChordoma_CIRT_cancers_2023.pdf The aim of this study is to apply dosiomics analysis using biological dose maps and LET d (dose-averaged Linear Energy Transfer) to predict local recurrence in sacral chordomas after carbon-ion radiotherapy. The authors used AI models, specifically regularized Cox proportional hazards models and survival support vector machines, to analyze features extracted from these maps and conventional DVH metrics.\n",
      "Tumor control probability (TCP) prediction ../database/selected_articles/Parrella_Dosiomics_CIRT_SBC_PhyMed_2024.pdf The aim is to investigate the role of dosiomics features from physical dose (D PHYS), RBE-weighted dose (D RBE), and dose-averaged Linear Energy Transfer (LETd) in predicting local recurrence (LR) in skull base chordomas treated with Carbon Ion Radiotherapy (CIRT). The study also evaluates dosiomics-driven tumor control probability (TCP) models.\n",
      "Tumor control probability (TCP) prediction ../database/selected_articles/Zhang_Predicting_Weight_Loss_PT_2018_JJCO.pdf The aim of the study is to investigate the predictors of critical weight loss (defined as >5%) in cancer patients undergoing particle therapy and to develop a prediction model based on these factors.\n",
      "Treatment planning, optimization and verification ../database/selected_articles/Li_NTCP_Dermatitis_HNC_CIRT_RedJ_2022.pdf To accurately perform the literature review as per the user's instructions, I need to carefully read and analyze the provided article, answer each question based on its content, then synthesize these answers into the required summaries.\n",
      "Normal tissue complication probability (NTCP) prediction ../database/selected_articles/Zhang_SPHIC_xerostomia_NTCP_PT_HeavyIonPT_012025.pdf The aim of this study is to evaluate machine learning models for predicting xerostomia in adults undergoing proton and carbon ion radiotherapy for head and neck cancer. The primary focus is on grade 2+ xerostomia, which is a significant side effect affecting patients' quality of life.\n",
      "Normal tissue complication probability (NTCP) prediction ../database/selected_articles/Meng_NTCP_HNC_CIRT_rad_dosiomics_012025.pdf The aim is to develop an NTCP model for predicting grade ≥2 AOM in HN cancer patients undergoing CIRT using AI techniques like radiomics, dosiomics, and DVH parameters.\n",
      "Treatment planning, optimization and verification ../database/selected_articles/Yabe_DoseDistribPrediction_DL_PT_2020_MP.pdf The aim of this study is to predict dose distributions in water from measured luminescence images using a deep convolutional neural network (DCNN) for particle therapy, including protons and carbon ions. The authors propose this method as an alternative to time-consuming Monte Carlo simulations for correcting Cerenkov light contamination.\n",
      "Treatment planning, optimization and verification ../database/selected_articles/Zhang_DL_Denoising_MC_DoseCalculationCIRT_MP_2023.pdf To evaluate the feasibility of using deep learning-based MC denoising to accelerate carbon-ion radiotherapy plan verification by comparing CycleGAN, 3D UNet, and GhostUNet models.\n",
      "Treatment planning, optimization and verification ../database/selected_articles/Quarz_DL_Sampling_TPS_PMB_2024_new.pdf The aim of the study was to develop a deep learning-based method for reducing the number of voxels used in treatment plan optimization for carbon ion therapy, thereby improving computational efficiency without significantly compromising plan quality.\n",
      "Treatment planning, optimization and verification ../database/selected_articles/He_Deep learning‐based Monte Carlo dose prediction for heavy‐ion online adaptive radiotherapy_MP_2025.pdf The aim is to develop a DL model for predicting Monte Carlo doses in heavy-ion therapy to facilitate OART and rapid QA.\n",
      "Treatment planning, optimization and verification ../database/selected_articles/Yamaguchi_DoseImagePrediction_range_width_verifications_fromCIinduced_MP2020.pdf The aim is to use deep learning to convert SEB x-ray images into accurate dose images for better beam range and width estimation in carbon ion therapy.\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "\n",
    "articles_df = pd.read_excel(\"../database/articles_to_review.xlsx\")\n",
    "\n",
    "for i,row in tqdm(list(articles_df.iterrows())):\n",
    "\n",
    "    row_dict = row.to_dict()\n",
    "\n",
    "    file_path = os.path.join(DB_PATH, row_dict['path'])\n",
    "\n",
    "    loader = PyMuPDF4LLMLoader(file_path, mode='single') #we are loading all the pages of the documents in a single page\n",
    "    docs = loader.load()\n",
    "    manuscript = docs[0].page_content\n",
    "\n",
    "    # Keep everything except contents inside \"References\"\n",
    "    pattern = re.compile(r'^[#\\*\\s]*references\\b', re.IGNORECASE | re.MULTILINE)\n",
    "    match = pattern.search(manuscript)\n",
    "    if match:\n",
    "        ref_index = match.start()\n",
    "        manuscript = manuscript[:ref_index + len(match.group(0))]\n",
    "\n",
    "    output = dict(chain.invoke({\"article\":manuscript, \"topic\":\"APPLICATIONS OF AI IN CARBON ION THERAPY\"}))\n",
    "    output[\"file_path\"] = file_path\n",
    "\n",
    "    output = {**row_dict, **output}\n",
    "\n",
    "    print(output[\"category\"], file_path, output['aim'])\n",
    "\n",
    "    outputs.append(output)\n",
    "\n",
    "  \n",
    "pd.DataFrame(outputs).to_csv(os.path.join(OUT_DIR, \"ai_review_final.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
